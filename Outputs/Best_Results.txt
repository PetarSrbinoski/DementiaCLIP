Run timestamp: 20251017_234935
Base dir: C:\Users\petar\PycharmProjects\DementiaCLIP
Python: C:\Users\petar\PycharmProjects\DementiaCLIP\.venv\Scripts\python.exe


===== MODE: vision_only =====
============================================================
[Hardware Check]
============================================================
Using device: NVIDIA GeForce RTX 4050 Laptop GPU
============================================================

Starting training: vision_only on cuda

warning: in the working copy of '.idea/workspace.xml', LF will be replaced by CRLF the next time Git touches it

--- Fold 1/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 132,866
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/20 - Train Loss: 0.4247, Val Loss: 0.3775 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.4731
Epoch 2/20 - Train Loss: 0.3651, Val Loss: 0.3958 | Acc: 0.3559, F1: 0.2069, ROC-AUC: 0.3647
Epoch 3/20 - Train Loss: 0.3367, Val Loss: 0.4075 | Acc: 0.3559, F1: 0.2927, ROC-AUC: 0.3712
Epoch 4/20 - Train Loss: 0.3423, Val Loss: 0.4065 | Acc: 0.3729, F1: 0.3332, ROC-AUC: 0.4115
Epoch 5/20 - Train Loss: 0.3432, Val Loss: 0.3932 | Acc: 0.3898, F1: 0.3782, ROC-AUC: 0.4436
Epoch 6/20 - Train Loss: 0.3341, Val Loss: 0.4910 | Acc: 0.3220, F1: 0.1920, ROC-AUC: 0.4609
Epoch 7/20 - Train Loss: 0.3404, Val Loss: 0.4005 | Acc: 0.4068, F1: 0.4126, ROC-AUC: 0.4013
Epoch 8/20 - Train Loss: 0.3216, Val Loss: 0.4191 | Acc: 0.4068, F1: 0.3810, ROC-AUC: 0.4179
Epoch 9/20 - Train Loss: 0.3316, Val Loss: 0.4468 | Acc: 0.3729, F1: 0.3191, ROC-AUC: 0.4167
Early stopping at epoch 9 (no AUC improvement)
Fold 1 - Acc: 0.3729, F1: 0.3191, ROC-AUC: 0.4167

--- Fold 2/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 132,866
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/20 - Train Loss: 0.4084, Val Loss: 0.3760 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.5077
Epoch 2/20 - Train Loss: 0.3779, Val Loss: 0.3835 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.5103
Epoch 3/20 - Train Loss: 0.3594, Val Loss: 0.3562 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.5231
Epoch 4/20 - Train Loss: 0.3615, Val Loss: 0.3819 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.5763
Epoch 5/20 - Train Loss: 0.3590, Val Loss: 0.3711 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.6212
Epoch 6/20 - Train Loss: 0.3284, Val Loss: 0.3468 | Acc: 0.4407, F1: 0.3927, ROC-AUC: 0.6295
Epoch 7/20 - Train Loss: 0.3292, Val Loss: 0.3943 | Acc: 0.3898, F1: 0.2728, ROC-AUC: 0.6064
Epoch 8/20 - Train Loss: 0.3477, Val Loss: 0.3843 | Acc: 0.3390, F1: 0.1995, ROC-AUC: 0.6135
Epoch 9/20 - Train Loss: 0.3033, Val Loss: 0.3615 | Acc: 0.3559, F1: 0.2927, ROC-AUC: 0.6013
Epoch 10/20 - Train Loss: 0.3237, Val Loss: 0.3657 | Acc: 0.3729, F1: 0.3030, ROC-AUC: 0.6115

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.41e-06

Epoch 11/20 - Train Loss: 0.3186, Val Loss: 0.3578 | Acc: 0.4237, F1: 0.3810, ROC-AUC: 0.6090
Epoch 12/20 - Train Loss: 0.3175, Val Loss: 0.3759 | Acc: 0.4068, F1: 0.3406, ROC-AUC: 0.6058
Epoch 13/20 - Train Loss: 0.3059, Val Loss: 0.3574 | Acc: 0.4068, F1: 0.3693, ROC-AUC: 0.5962
Epoch 14/20 - Train Loss: 0.3101, Val Loss: 0.3633 | Acc: 0.4237, F1: 0.3932, ROC-AUC: 0.6019
Early stopping at epoch 14 (no AUC improvement)
Fold 2 - Acc: 0.4237, F1: 0.3932, ROC-AUC: 0.6019

--- Fold 3/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 132,866
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/20 - Train Loss: 0.3806, Val Loss: 0.3718 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.6686
Epoch 2/20 - Train Loss: 0.3695, Val Loss: 0.3438 | Acc: 0.3559, F1: 0.2324, ROC-AUC: 0.6474
Epoch 3/20 - Train Loss: 0.3630, Val Loss: 0.3807 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.6583
Epoch 4/20 - Train Loss: 0.3561, Val Loss: 0.3432 | Acc: 0.5424, F1: 0.5224, ROC-AUC: 0.5577
Epoch 5/20 - Train Loss: 0.3418, Val Loss: 0.3737 | Acc: 0.4237, F1: 0.3335, ROC-AUC: 0.6199
Epoch 6/20 - Train Loss: 0.3325, Val Loss: 0.3497 | Acc: 0.4407, F1: 0.4339, ROC-AUC: 0.5885
Epoch 7/20 - Train Loss: 0.3453, Val Loss: 0.3854 | Acc: 0.4068, F1: 0.3559, ROC-AUC: 0.5083
Epoch 8/20 - Train Loss: 0.3265, Val Loss: 0.3538 | Acc: 0.4915, F1: 0.5018, ROC-AUC: 0.5199
Epoch 9/20 - Train Loss: 0.3184, Val Loss: 0.4120 | Acc: 0.3729, F1: 0.3030, ROC-AUC: 0.5250
Early stopping at epoch 9 (no AUC improvement)
Fold 3 - Acc: 0.3729, F1: 0.3030, ROC-AUC: 0.5250

--- Fold 4/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 132,866
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/20 - Train Loss: 0.3985, Val Loss: 0.3793 | Acc: 0.3448, F1: 0.1768, ROC-AUC: 0.4961
Epoch 2/20 - Train Loss: 0.3741, Val Loss: 0.4191 | Acc: 0.3448, F1: 0.1768, ROC-AUC: 0.5428
Epoch 3/20 - Train Loss: 0.3767, Val Loss: 0.3557 | Acc: 0.3448, F1: 0.2052, ROC-AUC: 0.5270
Epoch 4/20 - Train Loss: 0.3373, Val Loss: 0.3769 | Acc: 0.3448, F1: 0.1768, ROC-AUC: 0.5368
Epoch 5/20 - Train Loss: 0.3395, Val Loss: 0.3702 | Acc: 0.3793, F1: 0.2707, ROC-AUC: 0.5355
Epoch 6/20 - Train Loss: 0.3385, Val Loss: 0.4198 | Acc: 0.3448, F1: 0.1768, ROC-AUC: 0.5645
Epoch 7/20 - Train Loss: 0.3650, Val Loss: 0.3749 | Acc: 0.3966, F1: 0.2798, ROC-AUC: 0.5704
Epoch 8/20 - Train Loss: 0.3374, Val Loss: 0.3625 | Acc: 0.4655, F1: 0.4260, ROC-AUC: 0.5737
Epoch 9/20 - Train Loss: 0.3210, Val Loss: 0.3925 | Acc: 0.4310, F1: 0.3751, ROC-AUC: 0.5691
Epoch 10/20 - Train Loss: 0.3382, Val Loss: 0.3755 | Acc: 0.4310, F1: 0.3751, ROC-AUC: 0.5796

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.41e-06

Epoch 11/20 - Train Loss: 0.3147, Val Loss: 0.3877 | Acc: 0.3793, F1: 0.2707, ROC-AUC: 0.5671
Epoch 12/20 - Train Loss: 0.3309, Val Loss: 0.3651 | Acc: 0.4655, F1: 0.4260, ROC-AUC: 0.5566
Epoch 13/20 - Train Loss: 0.3216, Val Loss: 0.3617 | Acc: 0.4483, F1: 0.4244, ROC-AUC: 0.5553
Epoch 14/20 - Train Loss: 0.3108, Val Loss: 0.3827 | Acc: 0.4138, F1: 0.3309, ROC-AUC: 0.5625
Epoch 15/20 - Train Loss: 0.2916, Val Loss: 0.3694 | Acc: 0.4655, F1: 0.4373, ROC-AUC: 0.5586
Epoch 16/20 - Train Loss: 0.3028, Val Loss: 0.3776 | Acc: 0.4310, F1: 0.3751, ROC-AUC: 0.5770
Epoch 17/20 - Train Loss: 0.3298, Val Loss: 0.3808 | Acc: 0.4310, F1: 0.3751, ROC-AUC: 0.5895
Epoch 18/20 - Train Loss: 0.3124, Val Loss: 0.3735 | Acc: 0.4655, F1: 0.4373, ROC-AUC: 0.5816
Epoch 19/20 - Train Loss: 0.3193, Val Loss: 0.3717 | Acc: 0.4655, F1: 0.4373, ROC-AUC: 0.5776
Epoch 20/20 - Train Loss: 0.2879, Val Loss: 0.3765 | Acc: 0.4483, F1: 0.4009, ROC-AUC: 0.5796
Fold 4 - Acc: 0.4483, F1: 0.4009, ROC-AUC: 0.5796

--- Fold 5/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 132,866
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/20 - Train Loss: 0.3737, Val Loss: 0.3544 | Acc: 0.3448, F1: 0.2234, ROC-AUC: 0.5020
Epoch 2/20 - Train Loss: 0.3441, Val Loss: 0.4320 | Acc: 0.3276, F1: 0.1617, ROC-AUC: 0.4872
Epoch 3/20 - Train Loss: 0.3703, Val Loss: 0.3899 | Acc: 0.3276, F1: 0.1900, ROC-AUC: 0.4946
Epoch 4/20 - Train Loss: 0.3371, Val Loss: 0.3814 | Acc: 0.3966, F1: 0.3331, ROC-AUC: 0.5094
Epoch 5/20 - Train Loss: 0.3566, Val Loss: 0.3720 | Acc: 0.3793, F1: 0.3223, ROC-AUC: 0.5094
Epoch 6/20 - Train Loss: 0.3293, Val Loss: 0.4434 | Acc: 0.3793, F1: 0.3053, ROC-AUC: 0.4332
Epoch 7/20 - Train Loss: 0.3496, Val Loss: 0.3852 | Acc: 0.3276, F1: 0.2569, ROC-AUC: 0.4271
Epoch 8/20 - Train Loss: 0.3302, Val Loss: 0.4211 | Acc: 0.3793, F1: 0.3223, ROC-AUC: 0.3941
Epoch 9/20 - Train Loss: 0.3214, Val Loss: 0.4054 | Acc: 0.3448, F1: 0.1974, ROC-AUC: 0.4818
Epoch 10/20 - Train Loss: 0.3220, Val Loss: 0.3758 | Acc: 0.3793, F1: 0.2643, ROC-AUC: 0.5526

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.41e-06

Epoch 11/20 - Train Loss: 0.3411, Val Loss: 0.3614 | Acc: 0.3793, F1: 0.3502, ROC-AUC: 0.5250
Epoch 12/20 - Train Loss: 0.3258, Val Loss: 0.3963 | Acc: 0.3621, F1: 0.3257, ROC-AUC: 0.4453
Epoch 13/20 - Train Loss: 0.2983, Val Loss: 0.3914 | Acc: 0.3621, F1: 0.3382, ROC-AUC: 0.4528
Epoch 14/20 - Train Loss: 0.2970, Val Loss: 0.4249 | Acc: 0.3621, F1: 0.3257, ROC-AUC: 0.4575
Epoch 15/20 - Train Loss: 0.2991, Val Loss: 0.4028 | Acc: 0.3793, F1: 0.3502, ROC-AUC: 0.4669
Epoch 16/20 - Train Loss: 0.3084, Val Loss: 0.3931 | Acc: 0.3621, F1: 0.3114, ROC-AUC: 0.4899
Epoch 17/20 - Train Loss: 0.2978, Val Loss: 0.3974 | Acc: 0.3448, F1: 0.2667, ROC-AUC: 0.4953
Epoch 18/20 - Train Loss: 0.3123, Val Loss: 0.4003 | Acc: 0.3276, F1: 0.2569, ROC-AUC: 0.4798
Early stopping at epoch 18 (no AUC improvement)
Fold 5 - Acc: 0.3276, F1: 0.2569, ROC-AUC: 0.4798

==================================================
Mode: vision_only
Avg Accuracy: 0.3891, Avg F1: 0.3346, Avg ROC-AUC: 0.5206
==================================================

Training complete.



===== MODE: multimodal_basic =====
============================================================
[Hardware Check]
============================================================
Using device: NVIDIA GeForce RTX 4050 Laptop GPU
============================================================

Starting training: multimodal_basic on cuda

warning: in the working copy of '.idea/workspace.xml', LF will be replaced by CRLF the next time Git touches it

--- Fold 1/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 264,962
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3766, Val Loss: 0.3693 | Acc: 0.3559, F1: 0.2069, ROC-AUC: 0.7135
Epoch 2/30 - Train Loss: 0.3149, Val Loss: 0.3341 | Acc: 0.4407, F1: 0.3620, ROC-AUC: 0.7872
Epoch 3/30 - Train Loss: 0.2752, Val Loss: 0.3078 | Acc: 0.5932, F1: 0.5855, ROC-AUC: 0.7731
Epoch 4/30 - Train Loss: 0.2495, Val Loss: 0.2792 | Acc: 0.6610, F1: 0.6700, ROC-AUC: 0.7718
Epoch 5/30 - Train Loss: 0.2209, Val Loss: 0.2449 | Acc: 0.7458, F1: 0.7525, ROC-AUC: 0.8295
Epoch 6/30 - Train Loss: 0.1959, Val Loss: 0.2472 | Acc: 0.7288, F1: 0.7360, ROC-AUC: 0.8436
Epoch 7/30 - Train Loss: 0.1847, Val Loss: 0.2753 | Acc: 0.7288, F1: 0.7317, ROC-AUC: 0.7974
Epoch 8/30 - Train Loss: 0.1620, Val Loss: 0.2475 | Acc: 0.7458, F1: 0.7522, ROC-AUC: 0.8397
Epoch 9/30 - Train Loss: 0.1316, Val Loss: 0.2593 | Acc: 0.7797, F1: 0.7782, ROC-AUC: 0.8365
Epoch 10/30 - Train Loss: 0.1436, Val Loss: 0.2844 | Acc: 0.7288, F1: 0.7338, ROC-AUC: 0.8038

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1445, Val Loss: 0.2903 | Acc: 0.7288, F1: 0.7146, ROC-AUC: 0.8346
Epoch 12/30 - Train Loss: 0.1205, Val Loss: 0.2782 | Acc: 0.7627, F1: 0.7689, ROC-AUC: 0.8295
Epoch 13/30 - Train Loss: 0.0856, Val Loss: 0.3070 | Acc: 0.7797, F1: 0.7782, ROC-AUC: 0.8263
Epoch 14/30 - Train Loss: 0.0821, Val Loss: 0.2808 | Acc: 0.7966, F1: 0.8014, ROC-AUC: 0.8372
Early stopping at epoch 14 (no AUC improvement)
Fold 1 - Acc: 0.7966, F1: 0.8014, ROC-AUC: 0.8372

--- Fold 2/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 264,962
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.4532, Val Loss: 0.3625 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.6712
Epoch 2/30 - Train Loss: 0.3545, Val Loss: 0.3329 | Acc: 0.3898, F1: 0.2728, ROC-AUC: 0.7455
Epoch 3/30 - Train Loss: 0.3114, Val Loss: 0.3073 | Acc: 0.5085, F1: 0.4663, ROC-AUC: 0.8205
Epoch 4/30 - Train Loss: 0.2538, Val Loss: 0.2776 | Acc: 0.6271, F1: 0.6200, ROC-AUC: 0.8436
Epoch 5/30 - Train Loss: 0.2272, Val Loss: 0.2449 | Acc: 0.7288, F1: 0.7360, ROC-AUC: 0.8564
Epoch 6/30 - Train Loss: 0.1893, Val Loss: 0.2327 | Acc: 0.7458, F1: 0.7525, ROC-AUC: 0.8769
Epoch 7/30 - Train Loss: 0.1719, Val Loss: 0.3512 | Acc: 0.5763, F1: 0.5578, ROC-AUC: 0.8564
Epoch 8/30 - Train Loss: 0.1845, Val Loss: 0.2812 | Acc: 0.6780, F1: 0.6780, ROC-AUC: 0.8577
Epoch 9/30 - Train Loss: 0.1703, Val Loss: 0.2968 | Acc: 0.6780, F1: 0.6780, ROC-AUC: 0.8564
Epoch 10/30 - Train Loss: 0.1480, Val Loss: 0.2362 | Acc: 0.7458, F1: 0.7525, ROC-AUC: 0.8385

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1463, Val Loss: 0.2499 | Acc: 0.7458, F1: 0.7515, ROC-AUC: 0.8359
Epoch 12/30 - Train Loss: 0.1337, Val Loss: 0.2369 | Acc: 0.7627, F1: 0.7685, ROC-AUC: 0.8397
Epoch 13/30 - Train Loss: 0.1161, Val Loss: 0.2325 | Acc: 0.7458, F1: 0.7523, ROC-AUC: 0.8436
Epoch 14/30 - Train Loss: 0.0904, Val Loss: 0.2743 | Acc: 0.7119, F1: 0.7169, ROC-AUC: 0.8353
Early stopping at epoch 14 (no AUC improvement)
Fold 2 - Acc: 0.7119, F1: 0.7169, ROC-AUC: 0.8353

--- Fold 3/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 264,962
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3963, Val Loss: 0.4210 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.8423
Epoch 2/30 - Train Loss: 0.3411, Val Loss: 0.3114 | Acc: 0.4746, F1: 0.4160, ROC-AUC: 0.8776
Epoch 3/30 - Train Loss: 0.2954, Val Loss: 0.2844 | Acc: 0.6780, F1: 0.6780, ROC-AUC: 0.8821
Epoch 4/30 - Train Loss: 0.2312, Val Loss: 0.2555 | Acc: 0.7288, F1: 0.7355, ROC-AUC: 0.8487
Epoch 5/30 - Train Loss: 0.2119, Val Loss: 0.2444 | Acc: 0.7627, F1: 0.7685, ROC-AUC: 0.8705
Epoch 6/30 - Train Loss: 0.1919, Val Loss: 0.2404 | Acc: 0.7797, F1: 0.7809, ROC-AUC: 0.8500
Epoch 7/30 - Train Loss: 0.2102, Val Loss: 0.2444 | Acc: 0.7966, F1: 0.7938, ROC-AUC: 0.8410
Epoch 8/30 - Train Loss: 0.1712, Val Loss: 0.2425 | Acc: 0.7458, F1: 0.7512, ROC-AUC: 0.8385
Epoch 9/30 - Train Loss: 0.1649, Val Loss: 0.2414 | Acc: 0.7458, F1: 0.7512, ROC-AUC: 0.8385
Epoch 10/30 - Train Loss: 0.1599, Val Loss: 0.2439 | Acc: 0.7627, F1: 0.7594, ROC-AUC: 0.8474

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1459, Val Loss: 0.2545 | Acc: 0.7627, F1: 0.7594, ROC-AUC: 0.8462
Early stopping at epoch 11 (no AUC improvement)
Fold 3 - Acc: 0.7627, F1: 0.7594, ROC-AUC: 0.8462

--- Fold 4/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 264,962
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.4274, Val Loss: 0.3872 | Acc: 0.3793, F1: 0.2470, ROC-AUC: 0.6704
Epoch 2/30 - Train Loss: 0.3207, Val Loss: 0.3041 | Acc: 0.6207, F1: 0.6207, ROC-AUC: 0.8092
Epoch 3/30 - Train Loss: 0.2815, Val Loss: 0.2751 | Acc: 0.7069, F1: 0.7108, ROC-AUC: 0.8658
Epoch 4/30 - Train Loss: 0.2425, Val Loss: 0.2340 | Acc: 0.7414, F1: 0.7466, ROC-AUC: 0.8750
Epoch 5/30 - Train Loss: 0.2313, Val Loss: 0.2180 | Acc: 0.8103, F1: 0.8114, ROC-AUC: 0.8750
Epoch 6/30 - Train Loss: 0.2247, Val Loss: 0.2183 | Acc: 0.7931, F1: 0.7952, ROC-AUC: 0.8776
Epoch 7/30 - Train Loss: 0.1839, Val Loss: 0.2220 | Acc: 0.7586, F1: 0.7629, ROC-AUC: 0.8553
Epoch 8/30 - Train Loss: 0.1541, Val Loss: 0.2275 | Acc: 0.7069, F1: 0.7141, ROC-AUC: 0.8684
Epoch 9/30 - Train Loss: 0.1266, Val Loss: 0.2151 | Acc: 0.8276, F1: 0.8253, ROC-AUC: 0.8592
Epoch 10/30 - Train Loss: 0.1517, Val Loss: 0.2506 | Acc: 0.8276, F1: 0.8223, ROC-AUC: 0.8546

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1407, Val Loss: 0.2241 | Acc: 0.7586, F1: 0.7629, ROC-AUC: 0.8618
Epoch 12/30 - Train Loss: 0.1039, Val Loss: 0.2280 | Acc: 0.8448, F1: 0.8415, ROC-AUC: 0.8618
Epoch 13/30 - Train Loss: 0.1168, Val Loss: 0.2228 | Acc: 0.7586, F1: 0.7611, ROC-AUC: 0.8645
Epoch 14/30 - Train Loss: 0.1012, Val Loss: 0.2309 | Acc: 0.7586, F1: 0.7611, ROC-AUC: 0.8592
Early stopping at epoch 14 (no AUC improvement)
Fold 4 - Acc: 0.7586, F1: 0.7611, ROC-AUC: 0.8592

--- Fold 5/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 264,962
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3610, Val Loss: 0.3584 | Acc: 0.3966, F1: 0.3621, ROC-AUC: 0.5101
Epoch 2/30 - Train Loss: 0.3339, Val Loss: 0.3520 | Acc: 0.4138, F1: 0.3863, ROC-AUC: 0.6167
Epoch 3/30 - Train Loss: 0.2641, Val Loss: 0.3163 | Acc: 0.6897, F1: 0.6975, ROC-AUC: 0.6862
Epoch 4/30 - Train Loss: 0.2499, Val Loss: 0.2905 | Acc: 0.7069, F1: 0.7157, ROC-AUC: 0.7429
Epoch 5/30 - Train Loss: 0.1879, Val Loss: 0.2680 | Acc: 0.6897, F1: 0.6989, ROC-AUC: 0.7632
Epoch 6/30 - Train Loss: 0.2025, Val Loss: 0.2845 | Acc: 0.7069, F1: 0.7158, ROC-AUC: 0.7625
Epoch 7/30 - Train Loss: 0.1573, Val Loss: 0.3136 | Acc: 0.7241, F1: 0.7311, ROC-AUC: 0.7692
Epoch 8/30 - Train Loss: 0.1668, Val Loss: 0.3129 | Acc: 0.6552, F1: 0.6623, ROC-AUC: 0.7517
Epoch 9/30 - Train Loss: 0.1198, Val Loss: 0.3356 | Acc: 0.7069, F1: 0.7158, ROC-AUC: 0.7476
Epoch 10/30 - Train Loss: 0.1469, Val Loss: 0.3197 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7827

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1112, Val Loss: 0.3289 | Acc: 0.7586, F1: 0.7660, ROC-AUC: 0.7611
Epoch 12/30 - Train Loss: 0.1035, Val Loss: 0.3198 | Acc: 0.7414, F1: 0.7492, ROC-AUC: 0.7854
Epoch 13/30 - Train Loss: 0.0991, Val Loss: 0.3429 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7780
Epoch 14/30 - Train Loss: 0.0965, Val Loss: 0.2955 | Acc: 0.6897, F1: 0.6960, ROC-AUC: 0.7922
Epoch 15/30 - Train Loss: 0.0911, Val Loss: 0.3630 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7827
Epoch 16/30 - Train Loss: 0.0787, Val Loss: 0.3431 | Acc: 0.7414, F1: 0.7492, ROC-AUC: 0.7746
Epoch 17/30 - Train Loss: 0.0995, Val Loss: 0.3642 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7800
Epoch 18/30 - Train Loss: 0.0801, Val Loss: 0.3462 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7773
Epoch 19/30 - Train Loss: 0.0746, Val Loss: 0.3733 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7706
Epoch 20/30 - Train Loss: 0.0555, Val Loss: 0.3908 | Acc: 0.7241, F1: 0.7322, ROC-AUC: 0.7800
Epoch 21/30 - Train Loss: 0.0524, Val Loss: 0.3341 | Acc: 0.7414, F1: 0.7492, ROC-AUC: 0.7787
Epoch 22/30 - Train Loss: 0.0756, Val Loss: 0.3485 | Acc: 0.7414, F1: 0.7492, ROC-AUC: 0.7787
Early stopping at epoch 22 (no AUC improvement)
Fold 5 - Acc: 0.7414, F1: 0.7492, ROC-AUC: 0.7787

==================================================
Mode: multimodal_basic
Avg Accuracy: 0.7542, Avg F1: 0.7576, Avg ROC-AUC: 0.8313
==================================================

Training complete.



===== MODE: multimodal_full =====
============================================================
[Hardware Check]
============================================================
Using device: NVIDIA GeForce RTX 4050 Laptop GPU
============================================================

Starting training: multimodal_full on cuda

warning: in the working copy of '.idea/workspace.xml', LF will be replaced by CRLF the next time Git touches it

--- Fold 1/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 626,242
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3553, Val Loss: 0.3298 | Acc: 0.3559, F1: 0.2069, ROC-AUC: 0.8365
Epoch 2/30 - Train Loss: 0.3186, Val Loss: 0.2960 | Acc: 0.6271, F1: 0.6200, ROC-AUC: 0.8769
Epoch 3/30 - Train Loss: 0.2724, Val Loss: 0.2655 | Acc: 0.6610, F1: 0.6657, ROC-AUC: 0.8603
Epoch 4/30 - Train Loss: 0.2527, Val Loss: 0.2833 | Acc: 0.6610, F1: 0.6657, ROC-AUC: 0.8667
Epoch 5/30 - Train Loss: 0.2345, Val Loss: 0.2355 | Acc: 0.7288, F1: 0.7355, ROC-AUC: 0.8705
Epoch 6/30 - Train Loss: 0.1723, Val Loss: 0.1960 | Acc: 0.7627, F1: 0.7689, ROC-AUC: 0.9038
Epoch 7/30 - Train Loss: 0.1560, Val Loss: 0.2433 | Acc: 0.7119, F1: 0.7184, ROC-AUC: 0.9090
Epoch 8/30 - Train Loss: 0.2011, Val Loss: 0.2125 | Acc: 0.8136, F1: 0.8163, ROC-AUC: 0.8808
Epoch 9/30 - Train Loss: 0.1161, Val Loss: 0.2257 | Acc: 0.7966, F1: 0.7966, ROC-AUC: 0.8846
Epoch 10/30 - Train Loss: 0.1120, Val Loss: 0.2384 | Acc: 0.7797, F1: 0.7829, ROC-AUC: 0.8769

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.0684, Val Loss: 0.2234 | Acc: 0.8475, F1: 0.8465, ROC-AUC: 0.9064
Epoch 12/30 - Train Loss: 0.0795, Val Loss: 0.2332 | Acc: 0.8136, F1: 0.8163, ROC-AUC: 0.9026
Epoch 13/30 - Train Loss: 0.0667, Val Loss: 0.2325 | Acc: 0.8136, F1: 0.8175, ROC-AUC: 0.9026
Epoch 14/30 - Train Loss: 0.0609, Val Loss: 0.2560 | Acc: 0.7966, F1: 0.7988, ROC-AUC: 0.8981
Epoch 15/30 - Train Loss: 0.0598, Val Loss: 0.3002 | Acc: 0.8475, F1: 0.8441, ROC-AUC: 0.8878
Early stopping at epoch 15 (no AUC improvement)
Fold 1 - Acc: 0.8475, F1: 0.8441, ROC-AUC: 0.8878

--- Fold 2/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 626,242
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3538, Val Loss: 0.3662 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.7160
Epoch 2/30 - Train Loss: 0.3140, Val Loss: 0.3075 | Acc: 0.6102, F1: 0.6140, ROC-AUC: 0.7513
Epoch 3/30 - Train Loss: 0.2686, Val Loss: 0.3210 | Acc: 0.6441, F1: 0.6502, ROC-AUC: 0.7590
Epoch 4/30 - Train Loss: 0.2325, Val Loss: 0.3450 | Acc: 0.6441, F1: 0.6502, ROC-AUC: 0.7731
Epoch 5/30 - Train Loss: 0.1962, Val Loss: 0.2823 | Acc: 0.7288, F1: 0.7360, ROC-AUC: 0.7974
Epoch 6/30 - Train Loss: 0.1923, Val Loss: 0.2958 | Acc: 0.6780, F1: 0.6853, ROC-AUC: 0.8167
Epoch 7/30 - Train Loss: 0.1431, Val Loss: 0.2863 | Acc: 0.7119, F1: 0.7193, ROC-AUC: 0.8333
Epoch 8/30 - Train Loss: 0.1332, Val Loss: 0.2643 | Acc: 0.7627, F1: 0.7689, ROC-AUC: 0.8513
Epoch 9/30 - Train Loss: 0.1189, Val Loss: 0.2453 | Acc: 0.7966, F1: 0.8014, ROC-AUC: 0.8679
Epoch 10/30 - Train Loss: 0.0980, Val Loss: 0.3429 | Acc: 0.7119, F1: 0.7169, ROC-AUC: 0.8500

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.0618, Val Loss: 0.3625 | Acc: 0.7288, F1: 0.7343, ROC-AUC: 0.8410
Epoch 12/30 - Train Loss: 0.0977, Val Loss: 0.3217 | Acc: 0.8136, F1: 0.8123, ROC-AUC: 0.8494
Epoch 13/30 - Train Loss: 0.1063, Val Loss: 0.3142 | Acc: 0.7288, F1: 0.7360, ROC-AUC: 0.8590
Epoch 14/30 - Train Loss: 0.0719, Val Loss: 0.3040 | Acc: 0.7288, F1: 0.7360, ROC-AUC: 0.8577
Epoch 15/30 - Train Loss: 0.0635, Val Loss: 0.2923 | Acc: 0.7797, F1: 0.7829, ROC-AUC: 0.8615
Epoch 16/30 - Train Loss: 0.0496, Val Loss: 0.3166 | Acc: 0.7797, F1: 0.7844, ROC-AUC: 0.8590
Epoch 17/30 - Train Loss: 0.0815, Val Loss: 0.3111 | Acc: 0.7966, F1: 0.7988, ROC-AUC: 0.8679
Early stopping at epoch 17 (no AUC improvement)
Fold 2 - Acc: 0.7966, F1: 0.7988, ROC-AUC: 0.8679

--- Fold 3/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 626,242
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3644, Val Loss: 0.3502 | Acc: 0.3390, F1: 0.1716, ROC-AUC: 0.8378
Epoch 2/30 - Train Loss: 0.3413, Val Loss: 0.3228 | Acc: 0.4407, F1: 0.3620, ROC-AUC: 0.9212
Epoch 3/30 - Train Loss: 0.2823, Val Loss: 0.2520 | Acc: 0.7119, F1: 0.7147, ROC-AUC: 0.9346
Epoch 4/30 - Train Loss: 0.2331, Val Loss: 0.2073 | Acc: 0.7627, F1: 0.7685, ROC-AUC: 0.9372
Epoch 5/30 - Train Loss: 0.1994, Val Loss: 0.1967 | Acc: 0.8136, F1: 0.8183, ROC-AUC: 0.9179
Epoch 6/30 - Train Loss: 0.1848, Val Loss: 0.2031 | Acc: 0.8136, F1: 0.8184, ROC-AUC: 0.9192
Epoch 7/30 - Train Loss: 0.1595, Val Loss: 0.1904 | Acc: 0.8305, F1: 0.8350, ROC-AUC: 0.9244
Epoch 8/30 - Train Loss: 0.1478, Val Loss: 0.1921 | Acc: 0.8475, F1: 0.8515, ROC-AUC: 0.9205
Epoch 9/30 - Train Loss: 0.1232, Val Loss: 0.1878 | Acc: 0.8475, F1: 0.8515, ROC-AUC: 0.9141
Epoch 10/30 - Train Loss: 0.1109, Val Loss: 0.1764 | Acc: 0.8814, F1: 0.8843, ROC-AUC: 0.9115

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.0828, Val Loss: 0.2429 | Acc: 0.8136, F1: 0.8184, ROC-AUC: 0.9090
Epoch 12/30 - Train Loss: 0.0772, Val Loss: 0.1951 | Acc: 0.8644, F1: 0.8676, ROC-AUC: 0.9103
Early stopping at epoch 12 (no AUC improvement)
Fold 3 - Acc: 0.8644, F1: 0.8676, ROC-AUC: 0.9103

--- Fold 4/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 626,242
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3586, Val Loss: 0.3315 | Acc: 0.3793, F1: 0.2470, ROC-AUC: 0.8092
Epoch 2/30 - Train Loss: 0.3042, Val Loss: 0.3689 | Acc: 0.3793, F1: 0.2470, ROC-AUC: 0.8434
Epoch 3/30 - Train Loss: 0.2774, Val Loss: 0.2837 | Acc: 0.6724, F1: 0.6706, ROC-AUC: 0.8454
Epoch 4/30 - Train Loss: 0.2240, Val Loss: 0.2882 | Acc: 0.6552, F1: 0.6552, ROC-AUC: 0.8579
Epoch 5/30 - Train Loss: 0.2025, Val Loss: 0.2522 | Acc: 0.7069, F1: 0.7108, ROC-AUC: 0.8829
Epoch 6/30 - Train Loss: 0.1772, Val Loss: 0.2069 | Acc: 0.7586, F1: 0.7645, ROC-AUC: 0.8882
Epoch 7/30 - Train Loss: 0.1377, Val Loss: 0.2688 | Acc: 0.6724, F1: 0.6768, ROC-AUC: 0.8868
Epoch 8/30 - Train Loss: 0.0955, Val Loss: 0.2332 | Acc: 0.7586, F1: 0.7645, ROC-AUC: 0.8947
Epoch 9/30 - Train Loss: 0.1647, Val Loss: 0.2574 | Acc: 0.8448, F1: 0.8385, ROC-AUC: 0.8954
Epoch 10/30 - Train Loss: 0.1217, Val Loss: 0.2088 | Acc: 0.7759, F1: 0.7812, ROC-AUC: 0.9039

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1135, Val Loss: 0.2112 | Acc: 0.8103, F1: 0.8148, ROC-AUC: 0.9079
Epoch 12/30 - Train Loss: 0.0954, Val Loss: 0.2177 | Acc: 0.8103, F1: 0.8148, ROC-AUC: 0.9105
Epoch 13/30 - Train Loss: 0.1021, Val Loss: 0.2186 | Acc: 0.8448, F1: 0.8471, ROC-AUC: 0.9000
Epoch 14/30 - Train Loss: 0.0529, Val Loss: 0.2152 | Acc: 0.8448, F1: 0.8480, ROC-AUC: 0.9053
Epoch 15/30 - Train Loss: 0.0637, Val Loss: 0.2427 | Acc: 0.7931, F1: 0.7982, ROC-AUC: 0.9026
Epoch 16/30 - Train Loss: 0.0335, Val Loss: 0.2439 | Acc: 0.8448, F1: 0.8471, ROC-AUC: 0.8987
Epoch 17/30 - Train Loss: 0.0283, Val Loss: 0.2506 | Acc: 0.8276, F1: 0.8314, ROC-AUC: 0.8947
Epoch 18/30 - Train Loss: 0.0377, Val Loss: 0.2679 | Acc: 0.8276, F1: 0.8314, ROC-AUC: 0.8934
Epoch 19/30 - Train Loss: 0.0324, Val Loss: 0.2595 | Acc: 0.8276, F1: 0.8314, ROC-AUC: 0.8934
Epoch 20/30 - Train Loss: 0.0167, Val Loss: 0.2575 | Acc: 0.8448, F1: 0.8480, ROC-AUC: 0.8954
Early stopping at epoch 20 (no AUC improvement)
Fold 4 - Acc: 0.8448, F1: 0.8480, ROC-AUC: 0.8954

--- Fold 5/5 ---
Initializing model and data...
Fine-tuning CLIP: No (frozen for 10 epochs)
Batch size: 16
Trainable params: 626,242
[Scheduler] warmup_cosine | warmup=4 | min_lr_factor=0.05
Epoch 1/30 - Train Loss: 0.3448, Val Loss: 0.3616 | Acc: 0.3276, F1: 0.1617, ROC-AUC: 0.7308
Epoch 2/30 - Train Loss: 0.3067, Val Loss: 0.3044 | Acc: 0.6034, F1: 0.6124, ROC-AUC: 0.7382
Epoch 3/30 - Train Loss: 0.2896, Val Loss: 0.2796 | Acc: 0.6207, F1: 0.6307, ROC-AUC: 0.7584
Epoch 4/30 - Train Loss: 0.2715, Val Loss: 0.2617 | Acc: 0.6379, F1: 0.6439, ROC-AUC: 0.7800
Epoch 5/30 - Train Loss: 0.2124, Val Loss: 0.2545 | Acc: 0.7586, F1: 0.7650, ROC-AUC: 0.7996
Epoch 6/30 - Train Loss: 0.1884, Val Loss: 0.2457 | Acc: 0.7414, F1: 0.7487, ROC-AUC: 0.8151
Epoch 7/30 - Train Loss: 0.1495, Val Loss: 0.2384 | Acc: 0.7241, F1: 0.7324, ROC-AUC: 0.8340
Epoch 8/30 - Train Loss: 0.1360, Val Loss: 0.2509 | Acc: 0.7069, F1: 0.7149, ROC-AUC: 0.8529
Epoch 9/30 - Train Loss: 0.1531, Val Loss: 0.2608 | Acc: 0.7069, F1: 0.7149, ROC-AUC: 0.8596
Epoch 10/30 - Train Loss: 0.1075, Val Loss: 0.3002 | Acc: 0.7241, F1: 0.7199, ROC-AUC: 0.8246

Epoch 11: Fine-tuning CLIP ENABLED — unfroze last 1 block(s) + LayerNorms.
[LR] After unfreeze: CLIP LR -> 1.76e-06

Epoch 11/30 - Train Loss: 0.1083, Val Loss: 0.2589 | Acc: 0.7069, F1: 0.7139, ROC-AUC: 0.8327
Epoch 12/30 - Train Loss: 0.0733, Val Loss: 0.2510 | Acc: 0.7414, F1: 0.7493, ROC-AUC: 0.8543
Epoch 13/30 - Train Loss: 0.0871, Val Loss: 0.2655 | Acc: 0.7759, F1: 0.7812, ROC-AUC: 0.8489
Epoch 14/30 - Train Loss: 0.0633, Val Loss: 0.2788 | Acc: 0.7414, F1: 0.7487, ROC-AUC: 0.8381
Epoch 15/30 - Train Loss: 0.0658, Val Loss: 0.3120 | Acc: 0.7069, F1: 0.7158, ROC-AUC: 0.8313
Epoch 16/30 - Train Loss: 0.0479, Val Loss: 0.3447 | Acc: 0.7414, F1: 0.7395, ROC-AUC: 0.8327
Epoch 17/30 - Train Loss: 0.0370, Val Loss: 0.3411 | Acc: 0.7241, F1: 0.7298, ROC-AUC: 0.8219
Early stopping at epoch 17 (no AUC improvement)
Fold 5 - Acc: 0.7241, F1: 0.7298, ROC-AUC: 0.8219

==================================================
Mode: multimodal_full
Avg Accuracy: 0.8155, Avg F1: 0.8177, Avg ROC-AUC: 0.8767
==================================================

Training complete.

